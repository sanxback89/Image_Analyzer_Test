import streamlit as st
from openai import OpenAI
import base64
from PIL import Image
import plotly.graph_objects as go
import io
import json
from collections import Counter, defaultdict
import re
import random
import zipfile
import pandas as pd
import openpyxl
from openpyxl_image_loader import SheetImageLoader
import cv2
import numpy as np
import time
import colorsys

# OpenAI API í‚¤ ì„¤ì • (Streamlit Cloudì˜ secretsì—ì„œ ê°€ì ¸ì˜´)
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# í”„ë¡œê·¸ë ˆìŠ¤ ë°” ë° ìƒíƒœ ë©”ì‹œì§€ë¥¼ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
progress_bar = None
status_text = None

# ì‚¬ìš©ì ì¸ì¦ ë° ì‚¬ìš©ëŸ‰ ì¶”ì 
def authenticate_user():
    if "authenticated" not in st.session_state:
        st.session_state.authenticated = False
    
    if not st.session_state.authenticated:
        email = st.text_input("ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        if st.button("ì¸ì¦"):
            if email.endswith("@yakjin.com"):
                st.session_state.authenticated = True
                st.session_state.email = email
                st.success("ì¸ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.")
                return True
            else:
                st.error("í—ˆìš©ë˜ì§€ ì•Šì€ ì´ë©”ì¼ ì£¼ì†Œì…ë‹ˆë‹¤. @yakjin.com ë„ë©”ì¸ì˜ ì´ë©”ì¼ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                return False
    return st.session_state.authenticated

# ì—‘ì…€ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ ë° ZIP ìƒì„± í•¨ìˆ˜
def extract_images_from_excel(uploaded_file):
    # ë©”ëª¨ë¦¬ì—ì„œ ì—‘ì…€ íŒŒì¼ ì—´ê¸°
    wb = openpyxl.load_workbook(io.BytesIO(uploaded_file.getvalue()))
    sheet = wb.active
    image_loader = SheetImageLoader(sheet)
    
    # ì´ë¯¸ì§€ ì¶”ì¶œ
    images = []
    for row in sheet.iter_rows():
        for cell in row:
            try:
                if image_loader.image_in(cell.coordinate):
                    image = image_loader.get(cell.coordinate)
                    images.append(image)
            except Exception as e:
                # 'I/O operation on closed file' ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
                if "I/O operation on closed file" not in str(e):
                    st.warning(f"ì…€ {cell.coordinate}ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                continue
    
    return images

def enhance_image(image, scale_factor=2):
    # PIL Imageë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    
    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    height, width = cv_image.shape[:2]
    resized = cv2.resize(cv_image, (width*scale_factor, height*scale_factor), interpolation=cv2.INTER_CUBIC)
    
    # ì–¸ìƒ¤í”„ ë§ˆìŠ¤í¬ í•„í„° ì ìš©
    gaussian = cv2.GaussianBlur(resized, (0, 0), 3.0)
    sharpened = cv2.addWeighted(resized, 1.5, gaussian, -0.5, 0, resized)
    
    # ë…¸ì´ì¦ˆ ì œê±°
    denoised = cv2.fastNlMeansDenoisingColored(sharpened, None, 10, 10, 7, 21)
    
    # OpenCV í˜•ì‹ì„ ë‹¤ì‹œ PIL Imageë¡œ ë³€í™˜
    return Image.fromarray(cv2.cvtColor(denoised, cv2.COLOR_BGR2RGB))

# ì´ë¯¸ì§€ ë¶„ì„ ê´€ë ¨ í•¨ìˆ˜
def encode_image(image_file):
    return base64.b64encode(image_file.getvalue()).decode('utf-8')

def preprocess_response(response):
    json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
    if json_match:
        return json_match.group(1)
    return response

# ë¶„ì„ í•­ëª© ì •ì˜ (í™•ì¥ë¨)
analysis_options = {
    "Category": ["Top", "Bottom", "Dress", "Outerwear", "Accessories"],
    "Fit": ["Slim Fit", "Regular Fit", "Loose Fit", "Oversized", "Skinny", "Straight", "Bootcut", "Flare"],
    "Neckline": ["Crew Neck", "V-Neck", "Scoop Neck", "Turtleneck", "Cowl Neck", "Boat Neck", "Halter Neck", "Off-Shoulder", "Polo Collar", "Shirt Collar"],
    "Sleeves": ["Short Sleeves", "Long Sleeves", "Three-Quarter Sleeves", "Cap Sleeves", "Sleeveless", "Puff Sleeves"],
    "Length": ["Crop", "Regular", "Long", "Mini", "Midi", "Maxi"],
    "Color": ["Red", "Blue", "Green", "Yellow", "Purple", "Orange", "Pink", "Brown", "Black", "White", "Gray", "Multicolor"],
    "Pattern": ["Solid", "Striped", "Polka Dot", "Floral", "Plaid", "Checkered", "Animal Print"],
    "Material": ["Cotton", "Polyester", "Denim", "Leather", "Silk", "Wool", "Linen"],
    "Details": ["Ruffles", "Pleats", "Embroidery", "Sequins", "Beading", "AppliquÃ©", "Fringe", "Cutouts", "Draping", "Gathering", "Buttons", "Zippers", "Pockets"]
}

def analyze_image(image, options):
    base64_image = encode_image(image)
    
    prompt = "ì´ë¯¸ì§€ì— ìˆëŠ” íŒ¨ì…˜ ì•„ì´í…œì„ ë¶„ì„í•˜ê³  ë‹¤ìŒ ì¸¡ë©´ì— ëŒ€í•œ ìì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:\n\n"
    for option in options:
        prompt += f"{option}: ì´ë¯¸ì§€ì—ì„œ ê°€ì¥ ì ì ˆí•œ ì˜µì…˜ì„ ì„ íƒí•˜ê±°ë‚˜, í•´ë‹¹ë˜ëŠ” ê²½ìš° ìƒˆë¡œìš´ ê°’ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.\n"
    
    prompt += "\nê²°ê³¼ë¥¼ ì„ íƒëœ ì¸¡ë©´ì„ í‚¤ë¡œ í•˜ê³  ê°ì§€ëœ ì˜µì…˜ì„ ê°’ìœ¼ë¡œ í•˜ëŠ” JSON ê°ì²´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”. ì—¬ëŸ¬ ì˜µì…˜ì´ ê°ì§€ë˜ë©´ ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ë‚˜ì—´í•´ì£¼ì„¸ìš”."

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                    ]
                }
            ],
            max_tokens=500
        )
        
        result = response.choices[0].message.content.strip()
        return preprocess_response(result)
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""

def generate_sophisticated_colors(n, used_colors=None):
    if used_colors is None:
        used_colors = set()
    colors = []
    hue_step = 1.0 / n
    for i in range(n):
        attempts = 0
        while attempts < 100:
            hue = (i * hue_step + random.random() * 0.5 * hue_step) % 1.0
            saturation = 0.6 + random.random() * 0.2
            lightness = 0.5 + random.random() * 0.2
            r, g, b = [int(x * 255) for x in colorsys.hls_to_rgb(hue, lightness, saturation)]
            color = f"rgb({r},{g},{b})"
            if color not in used_colors:
                colors.append(color)
                used_colors.add(color)
                break
            attempts += 1
        if attempts == 100:
            colors.append(f"rgb({random.randint(0, 255)},{random.randint(0, 255)},{random.randint(0, 255)})")
    return colors, used_colors

def create_donut_chart(data, title, used_colors=None):
    labels = list(data.keys())
    values = list(data.values())
    
    is_color_category = title.lower() == "color"
    if is_color_category:
        colors = []
        for color in labels:
            if color.lower() == "white":
                colors.append("rgb(248, 248, 248)")
            else:
                colors.append(color)
    else:
        colors, used_colors = generate_sophisticated_colors(len(labels), used_colors)

    # í…ìŠ¤íŠ¸ ìƒ‰ìƒ ê²°ì •
    text_colors = []
    for color in colors:
        if is_color_category and color == "rgb(248, 248, 248)":
            text_color = 'black'
        elif is_color_category:
            text_color = 'white' if color.lower() in ['black', 'navy', 'dark blue', 'dark green'] else 'black'
        else:
            r, g, b = map(int, color.strip('rgb()').split(','))
            brightness = (r * 299 + g * 587 + b * 114) / 1000
            text_color = 'white' if brightness < 128 else 'black'
        text_colors.append(text_color)

    fig = go.Figure(data=[go.Pie(
        labels=labels,
        values=values, 
        hole=.4,
        marker=dict(colors=colors, line=dict(color='#FFFFFF', width=0)),
        textposition='inside',
        textinfo='percent',
        hoverinfo='label+value',
        hovertemplate='%{label}<br>Count: %{value}<extra></extra>',
        textfont=dict(size=12, color=text_colors),
        insidetextorientation='radial'
    )])
    
    fig.update_layout(
        title=dict(
            text=title.capitalize(),
            font=dict(size=31),
            y=0.95,
            x=0.5,
            xanchor='center',
            yanchor='top'
        ),
        font=dict(family="Arial", size=14),
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        height=470,
        margin=dict(l=20, r=20, t=60, b=20),
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=-0.2,
            xanchor="center",
            x=0.5
        )
    )
    return fig, used_colors

def process_zip_file(zip_file):
    image_files = []
    with zipfile.ZipFile(zip_file, 'r') as zip_ref:
        for file_name in zip_ref.namelist():
            if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                with zip_ref.open(file_name) as file:
                    image_files.append((file_name, io.BytesIO(file.read())))
    return image_files

# ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜ ìˆ˜ì • (ë‹¨ìˆœí™”)
def process_images(images):
    processed_images = []
    for image in images:
        # í•„ìš”í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ ë¡œì§ ì¶”ê°€
        # ì˜ˆ: image = some_processing_function(image)
        processed_images.append(image)
    return processed_images

def show_images_for_category(category, value, images):
    with st.expander(f"{category}: {value} (í´ë¦­í•˜ì—¬ ì´ë¯¸ì§€ ë³´ê¸°)", expanded=False):
        cols = st.columns(4)
        for i, img in enumerate(images):
            with cols[i % 4]:
                st.image(img, use_column_width=True)
                if st.button(f"ì „ì²´ í¬ê¸°ë¡œ ë³´ê¸° {i+1}", key=f"{category}_{value}_{i}"):
                    st.image(img, use_column_width=True)

# ë©”ì¸ ì•± ë¡œì§
def main():
    global progress_bar, status_text
    
    st.set_page_config(layout="wide")
    
    # CSSë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ëª¨ì§€ í¬ê¸° ì¡°ì ˆ
    st.markdown("""
    <style>
    .emoji-title {
        font-size: 2.4em;
    }
    .emoji {
        font-size: 0.8em;
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown("<h1 class='emoji-title'>íŒ¨ì…˜ ì´ë¯¸ì§€ ë¶„ì„ê¸°</h1>", unsafe_allow_html=True)
    
    if authenticate_user():
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        step1 = st.empty()
        step1.markdown("<h3><span class='emoji'>ğŸ“</span> 1ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ</h3>", unsafe_allow_html=True)
        uploaded_file = st.file_uploader("íŒŒì¼ ì„ íƒ", type=["xlsx", "xls", "png", "jpg", "jpeg", "zip"])
        
        if uploaded_file is not None:
            step1.empty()
            
            step2 = st.empty()
            step2.markdown("<h3><span class='emoji'>ğŸ–¼ï¸</span> 2ë‹¨ê³„: ì´ë¯¸ì§€ ì²˜ë¦¬</h3>", unsafe_allow_html=True)
            
            images = []
            if uploaded_file.type == "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" or uploaded_file.type == "application/vnd.ms-excel":
                try:
                    images = extract_images_from_excel(uploaded_file)
                    if images:
                        images = images[1:]  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€(ë¡œê³ ) ì œì™¸
                except Exception as e:
                    st.error(f"ì—‘ì…€ íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            elif uploaded_file.type.startswith('image/'):
                images = [Image.open(uploaded_file)]
            elif uploaded_file.type == 'application/zip':
                images = [Image.open(io.BytesIO(img_data)) for _, img_data in process_zip_file(uploaded_file)]
            
            if images:
                st.markdown(f"<p><span class='emoji'>âœ…</span> {len(images)}ê°œì˜ ì´ë¯¸ì§€ê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.</p>", unsafe_allow_html=True)
                
                processed_images = process_images(images)
                
                st.markdown("<h3><span class='emoji'>ğŸ”</span> 3ë‹¨ê³„: ë¶„ì„ ê²°ê³¼</h3>", unsafe_allow_html=True)
                
                selected_options = st.multiselect(
                    label="ë¶„ì„í•  í•­ëª© ì„ íƒ",
                    options=list(analysis_options.keys()),
                    key="analysis_options"
                )
                
                if st.button("ğŸš€ ë¶„ì„ ì‹œì‘"):
                    if not selected_options:
                        st.markdown("<p><span class='emoji'>âš ï¸</span> ë¶„ì„í•  í•­ëª©ì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.</p>", unsafe_allow_html=True)
                    else:
                        step2.empty()
                        
                        aggregated_results = {option: Counter() for option in selected_options}
                        image_categories = defaultdict(lambda: defaultdict(list))
                        
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        
                        for i, image in enumerate(processed_images):
                            progress = (i + 1) / len(processed_images)
                            progress_bar.progress(progress)
                            status_text.text(f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: {i+1}/{len(processed_images)}")
                            
                            img_byte_arr = io.BytesIO()
                            image.save(img_byte_arr, format='PNG')
                            img_byte_arr = img_byte_arr.getvalue()
                            
                            try:
                                result = analyze_image(io.BytesIO(img_byte_arr), selected_options)
                                if result:
                                    analysis_results = json.loads(result)
                                    for option, detected in analysis_results.items():
                                        if isinstance(detected, list):
                                            aggregated_results[option].update(detected)
                                            for value in detected:
                                                image_categories[option][value].append(image)
                                        elif isinstance(detected, str):
                                            aggregated_results[option][detected] += 1
                                            image_categories[option][detected].append(image)
                                        else:
                                            st.warning(f"ì´ë¯¸ì§€ {i+1}ì˜ {option}ì— ëŒ€í•´ ì˜ˆìƒì¹˜ ëª»í•œ ê²°ê³¼ í˜•ì‹ì…ë‹ˆë‹¤: {detected}")
                            except Exception as e:
                                st.error(f"ì´ë¯¸ì§€ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                                continue
                        
                        progress_bar.empty()
                        status_text.empty()
                        
                        st.markdown("<h3 style='text-align: center;'><span class='emoji'>ğŸ“Š</span> ë¶„ì„ ê²°ê³¼</h3>", unsafe_allow_html=True)
                        col1, col2 = st.columns(2)
                        used_colors = set()
                        for i, (option, results) in enumerate(aggregated_results.items()):
                            if results:
                                fig, used_colors = create_donut_chart(results, option, used_colors)
                                if i % 2 == 0:
                                    with col1:
                                        st.plotly_chart(fig, use_container_width=True)
                                        for value, count in results.items():
                                            show_images_for_category(option, value, image_categories[option][value])
                                else:
                                    with col2:
                                        st.plotly_chart(fig, use_container_width=True)
                                        for value, count in results.items():
                                            show_images_for_category(option, value, image_categories[option][value])
                            else:
                                st.write(f"{option}ì— ëŒ€í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
                        # ì‚¬ìš©ëŸ‰ ì¶”ì 
                        if "image_count" not in st.session_state:
                            st.session_state.image_count = 0
                        st.session_state.image_count += len(images)
                        st.write(f"ì´ ë¶„ì„ëœ ì´ë¯¸ì§€ ìˆ˜: {st.session_state.image_count}")
            else:
                st.markdown("<p><span class='emoji'>âš ï¸</span> ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>", unsafe_allow_html=True)
    
    progress_bar.empty()
    status_text.empty()

if __name__ == "__main__":
    main()

# Streamlit í…Œë§ˆ ì„¤ì •ì„ ìœ„í•œ CSS
st.markdown("""
<style>
    .stMultiSelect [data-baseweb="tag"] {
        background-color: #007AFF !important;
    }
    .stMultiSelect [data-baseweb="tag"] span {
        color: white !important;
    }
    .stProgress .st-bo {
        background-color: #4CD964;
    }
    .stProgress .st-bp {
        background-color: #E5E5EA;
    }
    .stSelectbox label, .stMultiSelect label, .stFileUploader label {
        font-size: 16px !important;
        color: rgba(49, 51, 63, 0.6) !important;
    }
</style>
""", unsafe_allow_html=True)
